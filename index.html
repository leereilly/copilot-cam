<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-sc        // Mouse move handler for model rotation
        function onMouseMove(event) {
            // Calculate normalized mouse position (-1 to +1)
            mousePosition.x = (event.clientX / window.innerWidth) * 2 - 1;
            mousePosition.y = -(event.clientY / window.innerHeight) * 2 + 1;
            
            // Calculate target rotation based on mouse position
            // Limit rotation to reasonable angles (Â±15 degrees)
            const maxRotation = Math.PI / 12; // 15 degrees
            targetRotationY = mousePosition.x * maxRotation;
            targetRotationX = -mousePosition.y * maxRotation * 0.5; // Fixed: negative sign to correct inversion
        }  <title>Copilot GLB Viewer</title>
    <style>
        body { margin: 0; overflow: hidden; }
        canvas { display: block; }
        .loading-info {
            position: absolute;
            top: 10px;
            left: 10px;
            color: white;
            background-color: rgba(0, 0, 0, 0.5);
            padding: 5px 10px;
            border-radius: 5px;
            font-family: Arial, sans-serif;
            z-index: 100;
            transition: opacity 0.5s;
        }
        #webcamVideo {
            display: none;
        }
    </style>
</head>
<body>
    <div class="loading-info" id="loadingInfo"></div>
    <video id="webcamVideo" autoplay playsinline muted style="display: none;"></video>
    <canvas id="gifCanvas" width="512" height="512" style="display: none;"></canvas>
    <!-- Include the script at the end of the body for better performance -->
    <script src="share-modal.js" defer></script>
    <script type="importmap">
        {
            "imports": {
                "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
                "three/addons/": "https://unpkg.com/three@0.160.0/examples/jsm/"
            }
        }
    </script>
    <script type="module">
        import * as THREE from 'three';
        import { OrbitControls } from 'three/addons/controls/OrbitControls.js';
        import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';

        // Create scene
        const scene = new THREE.Scene();
        scene.background = new THREE.Color(0x333333);

        // Create camera
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        camera.position.z = 5;

        // Create renderer
        const renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setPixelRatio(window.devicePixelRatio);
        renderer.outputColorSpace = THREE.SRGBColorSpace;
        renderer.shadowMap.enabled = true;
        renderer.shadowMap.type = THREE.PCFSoftShadowMap;
        renderer.toneMapping = THREE.ACESFilmicToneMapping;
        renderer.toneMappingExposure = 1.0;
        document.body.appendChild(renderer.domElement);

        // Add lights
        const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
        scene.add(ambientLight);

        const directionalLight = new THREE.DirectionalLight(0xffffff, 1);
        directionalLight.position.set(5, 10, 7.5);
        directionalLight.castShadow = true;
        scene.add(directionalLight);
        
        // Add point lights for better metallic reflections
        const pointLight1 = new THREE.PointLight(0xffffff, 1, 50);
        pointLight1.position.set(0, 10, 10);
        scene.add(pointLight1);
        
        const pointLight2 = new THREE.PointLight(0xffffff, 0.8, 50);
        pointLight2.position.set(-10, -5, -10);
        scene.add(pointLight2);

        // Add orbit controls
        const controls = new OrbitControls(camera, renderer.domElement);
        controls.enableDamping = true;
        controls.dampingFactor = 0.05;

        // Add raycaster for mesh identification
        const raycaster = new THREE.Raycaster();
        const mouse = new THREE.Vector2();
        let modelGroupRef = null;
        
        // Mouse tracking for model rotation
        const mousePosition = new THREE.Vector2();
        let targetRotationX = 0;
        let targetRotationY = 0;
        const rotationSmoothness = 0.02; // Lower values = smoother/slower rotation

        // Mouse press handler to identify meshes and trigger blink
        function onMouseDown(event) {
            // Trigger blink animation on mouse press
            if (!isBlinking) {
                isBlinking = true;
                blinkProgress = 0;
            }
            
            if (!modelGroupRef) return;
            
            // Calculate mouse position in normalized device coordinates (-1 to +1)
            mouse.x = (event.clientX / window.innerWidth) * 2 - 1;
            mouse.y = -(event.clientY / window.innerHeight) * 2 + 1;

            // Update the raycaster
            raycaster.setFromCamera(mouse, camera);

            // Calculate objects intersecting the picking ray
            const intersects = raycaster.intersectObjects(modelGroupRef.children, true);

            if (intersects.length > 0) {
                const clickedMesh = intersects[0].object;
                
                // Find the mesh in our materials array
                const materialInfo = modelMaterials.find(item => item.mesh === clickedMesh);
                if (materialInfo) {
                    // Mesh clicked - could add UI feedback here
                }
            }
        }

        // Add mousedown event listener
        window.addEventListener('mousedown', onMouseDown, false);
        
        // Add mouse move event listener for model tracking
        window.addEventListener('mousemove', onMouseMove, false);
        
        // Mouse move handler for model rotation
        function onMouseMove(event) {
            // Calculate normalized mouse position (-1 to +1)
            mousePosition.x = (event.clientX / window.innerWidth) * 2 - 1;
            mousePosition.y = -(event.clientY / window.innerHeight) * 2 + 1;
            
            // Calculate target rotation based on mouse position
            // Limit rotation to reasonable angles (Â±15 degrees)
            const maxRotation = Math.PI / 12; // 15 degrees
            targetRotationY = mousePosition.x * maxRotation;
            targetRotationX = -mousePosition.y * maxRotation * 0.5; // Inverted Y for correct up/down direction
        }

        // Initialize webcam
        const webcamVideo = document.getElementById('webcamVideo');
        const webcamTexture = new THREE.VideoTexture(webcamVideo);
        webcamTexture.minFilter = THREE.LinearFilter;
        webcamTexture.magFilter = THREE.LinearFilter;
        webcamTexture.format = THREE.RGBAFormat;
        webcamTexture.wrapS = THREE.ClampToEdgeWrapping;
        webcamTexture.wrapT = THREE.ClampToEdgeWrapping;
        webcamTexture.flipY = false;
        
        // Initialize GIF canvas for right lens
        const gifCanvas = document.getElementById('gifCanvas');
        const gifContext = gifCanvas.getContext('2d');
        
        // Create an initial colorful pattern on the canvas to test if texture is working
        function createInitialTestPattern() {
            console.log('Creating initial test pattern on GIF canvas');
            
            // Create a bright test pattern
            gifContext.fillStyle = '#FF0000'; // Red background
            gifContext.fillRect(0, 0, gifCanvas.width, gifCanvas.height);
            
            // Add some blue squares
            gifContext.fillStyle = '#0000FF';
            for (let i = 0; i < 4; i++) {
                for (let j = 0; j < 4; j++) {
                    if ((i + j) % 2 === 0) {
                        gifContext.fillRect(i * 128, j * 128, 64, 64);
                    }
                }
            }
            
            // Add text
            gifContext.fillStyle = '#FFFFFF';
            gifContext.font = 'bold 32px Arial';
            gifContext.textAlign = 'center';
            gifContext.fillText('TEST', gifCanvas.width / 2, gifCanvas.height / 2);
            gifContext.fillText('PATTERN', gifCanvas.width / 2, gifCanvas.height / 2 + 40);
        }
        
        // Create initial test pattern
        createInitialTestPattern();
        
        let gifTexture = new THREE.CanvasTexture(gifCanvas);
        gifTexture.minFilter = THREE.LinearFilter;
        gifTexture.magFilter = THREE.LinearFilter;
        gifTexture.format = THREE.RGBAFormat;
        gifTexture.wrapS = THREE.ClampToEdgeWrapping;
        gifTexture.wrapT = THREE.ClampToEdgeWrapping;
        gifTexture.flipY = false;
        gifTexture.needsUpdate = true;
        
        // GIF state management
        let currentGifImage = null;
        let currentGifVideo = null;
        let gifFrames = [];
        let currentFrameIndex = 0;
        let gifFrameInterval = null;
        let isGifLoaded = false;
        let animationMode = 'none'; // 'video', 'image', 'fallback'
        let videoLoopCount = 0;
        let maxLoopsBeforeSwitch = 4;
        let lastSelectedVideoIndex = -1;
        
        // Function to get random meme video from hardcoded list
        function fetchRandomMemeGif() {
            console.log('Loading random meme video from hardcoded list...');
            
            // Use predefined animated video URLs
            const memeVideos = [
                'https://media.giphy.com/media/l3q2K5jinAlChoCLS/giphy.mp4',
                'https://media.giphy.com/media/LmNwrBhejkK9EFP504/giphy.mp4',
                'https://media0.giphy.com/media/v1.Y2lkPTc5MGI3NjExeWtsdmVyanI1YTQydHBjMmRjYm96ajhqd2h1Z3I4dWxuamdycDZrYSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/a7ZxXrkxd7S9eAl1Mr/giphy.mp4',
                'https://media0.giphy.com/media/v1.Y2lkPTc5MGI3NjExcWdzamhqenZubTE0YWRvcGlqZHkxcGtrMjhud3dyNXlidmIxYjg5ZiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/H5C8CevNMbpBqNqFjl/giphy.mp4',
                'https://media0.giphy.com/media/v1.Y2lkPTc5MGI3NjExNWdwNGV1ZmZpamRuaHdncHlnYzVzbWRjbHpmazBhcXo5dGh0bGIxeiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/AAsj7jdrHjtp6/giphy.mp4'
            ];
            
            // Avoid selecting the same video consecutively
            let randomIndex;
            do {
                randomIndex = Math.floor(Math.random() * memeVideos.length);
            } while (randomIndex === lastSelectedVideoIndex && memeVideos.length > 1);
            
            lastSelectedVideoIndex = randomIndex;
            const randomVideo = memeVideos[randomIndex];
            console.log('Selected video URL:', randomVideo, 'at index:', randomIndex);
            return randomVideo;
        }
        
        // Function to load and play video with proper animation support
        function loadGif() {
            console.log('Loading animated video...');
            
            // Reset loop count for new video
            videoLoopCount = 0;
            
            const videoUrl = fetchRandomMemeGif();
            
            if (videoUrl) {
                console.log('Attempting to load animated video from:', videoUrl);
                
                // Try to load as video first (should work with MP4 URLs)
                loadGifAsVideo(videoUrl).catch(error => {
                    console.warn('Failed to load as video, using fallback:', error);
                    createFallbackAnimation();
                });
            } else {
                console.log('No video URL available, using fallback animation');
                createFallbackAnimation();
            }
        }
        
        // Load video for animation support
        function loadGifAsVideo(videoUrl) {
            return new Promise((resolve, reject) => {
                const video = document.createElement('video');
                video.crossOrigin = 'anonymous';
                video.autoplay = true;
                video.loop = false; // Don't auto-loop so we can detect when it ends
                video.muted = true;
                video.playsInline = true;
                
                video.onloadeddata = () => {
                    console.log('Video loaded successfully, dimensions:', video.videoWidth, 'x', video.videoHeight);
                    currentGifVideo = video;
                    isGifLoaded = true;
                    startVideoGifAnimation();
                    resolve();
                };
                
                video.onerror = () => {
                    reject(new Error('Failed to load video'));
                };
                
                // Set timeout - shorter since we're using direct URLs
                setTimeout(() => {
                    if (!isGifLoaded) {
                        reject(new Error('Video loading timeout'));
                    }
                }, 5000); // 5 second timeout
                
                video.src = videoUrl;
            });
        }
        
        // Fallback animation when video loading fails
        function createFallbackAnimation() {
            console.log('Creating enhanced fallback animation');
            isGifLoaded = true;
            animationMode = 'fallback';
            
            // Update right lens with fallback animation
            updateRightLensWithGif();
            
            let animationFrame = 0;
            
            const animate = () => {
                // Create a more interesting animated pattern
                const time = animationFrame * 0.02;
                
                // Dynamic gradient background
                const gradient = gifContext.createRadialGradient(
                    gifCanvas.width / 2 + Math.sin(time) * 50, 
                    gifCanvas.height / 2 + Math.cos(time * 1.3) * 50, 
                    0,
                    gifCanvas.width / 2, 
                    gifCanvas.height / 2, 
                    Math.max(gifCanvas.width, gifCanvas.height) / 2
                );
                gradient.addColorStop(0, `hsl(${(time * 50) % 360}, 70%, 60%)`);
                gradient.addColorStop(0.5, `hsl(${(time * 50 + 120) % 360}, 80%, 50%)`);
                gradient.addColorStop(1, `hsl(${(time * 50 + 240) % 360}, 70%, 60%)`);
                
                gifContext.fillStyle = gradient;
                gifContext.fillRect(0, 0, gifCanvas.width, gifCanvas.height);
                
                // Add animated text with better effects
                gifContext.fillStyle = 'white';
                gifContext.font = 'bold 36px Arial';
                gifContext.textAlign = 'center';
                gifContext.shadowColor = 'black';
                gifContext.shadowBlur = 5;
                gifContext.shadowOffsetX = 2;
                gifContext.shadowOffsetY = 2;
                
                // Bouncing text
                const textY = gifCanvas.height / 2 + Math.sin(time * 3) * 10;
                gifContext.fillText('ðŸŽ­ MEME ðŸŽ­', gifCanvas.width / 2, textY - 40);
                gifContext.fillText('ZONE', gifCanvas.width / 2, textY);
                
                // Add animated dots with different timing
                const dots = Math.floor(time * 3) % 4;
                gifContext.font = 'bold 24px Arial';
                gifContext.fillText('.'.repeat(dots + 1), gifCanvas.width / 2, textY + 40);
                
                // Reset shadow
                gifContext.shadowBlur = 0;
                gifContext.shadowOffsetX = 0;
                gifContext.shadowOffsetY = 0;
                
                // Add more animated shapes
                for (let i = 0; i < 8; i++) {
                    gifContext.fillStyle = `hsla(${(time * 100 + i * 45) % 360}, 80%, 70%, 0.7)`;
                    const x = Math.sin(time + i * 0.8) * 120 + gifCanvas.width / 2;
                    const y = Math.cos(time * 1.2 + i * 0.8) * 90 + gifCanvas.height / 2;
                    const size = 15 + Math.sin(time * 4 + i) * 8;
                    
                    gifContext.beginPath();
                    gifContext.arc(x, y, size, 0, Math.PI * 2);
                    gifContext.fill();
                }
                
                // Add morphing shapes
                for (let i = 0; i < 4; i++) {
                    gifContext.save();
                    const x = 100 + i * 120;
                    const y = 100 + Math.sin(time * 2 + i) * 60;
                    gifContext.translate(x, y);
                    gifContext.rotate(time * 2 + i * 1.5);
                    
                    // Morphing between square and circle
                    const morphFactor = (Math.sin(time * 1.5 + i) + 1) / 2;
                    gifContext.fillStyle = `hsla(${(time * 80 + i * 90) % 360}, 90%, 60%, 0.8)`;
                    
                    if (morphFactor < 0.5) {
                        // Square
                        const size = 20 + morphFactor * 10;
                        gifContext.fillRect(-size / 2, -size / 2, size, size);
                    } else {
                        // Circle
                        const radius = 15 + (morphFactor - 0.5) * 15;
                        gifContext.beginPath();
                        gifContext.arc(0, 0, radius, 0, Math.PI * 2);
                        gifContext.fill();
                    }
                    
                    gifContext.restore();
                }
                
                // Add glitch effect occasionally
                if (Math.random() < 0.05) {
                    const glitchHeight = 10;
                    const glitchY = Math.random() * (gifCanvas.height - glitchHeight);
                    gifContext.fillStyle = `rgba(${Math.random() * 255}, ${Math.random() * 255}, ${Math.random() * 255}, 0.3)`;
                    gifContext.fillRect(0, glitchY, gifCanvas.width, glitchHeight);
                }
                
                gifTexture.needsUpdate = true;
                animationFrame++;
                
                if (animationMode === 'fallback') {
                    requestAnimationFrame(animate);
                }
            };
            
            animate();
        }
        
        // Function to start video-based GIF animation
        function startVideoGifAnimation() {
            if (!currentGifVideo) {
                console.warn('No GIF video available for animation');
                return;
            }
            
            console.log('Starting video GIF animation');
            animationMode = 'video';
            
            // Update right lens with GIF now that it's loaded
            updateRightLensWithGif();
            
            // Add event listener for video loop detection
            currentGifVideo.addEventListener('ended', () => {
                videoLoopCount++;
                console.log(`Video loop ${videoLoopCount}/${maxLoopsBeforeSwitch} completed`);
                
                if (videoLoopCount >= maxLoopsBeforeSwitch) {
                    console.log('Max loops reached, loading new video');
                    // Stop current animation
                    animationMode = 'none';
                    isGifLoaded = false;
                    // Load new video
                    loadGif();
                } else {
                    // Continue with current video by restarting it
                    console.log('Continuing with current video, restarting playback');
                    currentGifVideo.currentTime = 0;
                    currentGifVideo.play().catch(e => {
                        console.warn('Failed to restart video:', e);
                    });
                }
            });
            
            currentGifVideo.play().catch(e => {
                console.warn('Failed to play video:', e);
                // Fall back to image mode
                startImageGifAnimation();
            });
            
            let frame = 0;
            const animateVideoGif = () => {
                if (currentGifVideo && !currentGifVideo.paused) {
                    // Clear and draw video frame
                    gifContext.clearRect(0, 0, gifCanvas.width, gifCanvas.height);
                    
                    try {
                        // Draw the video frame to canvas
                        gifContext.drawImage(currentGifVideo, 0, 0, gifCanvas.width, gifCanvas.height);
                        
                        // Add subtle effects
                        const time = frame * 0.01;
                        gifContext.fillStyle = `rgba(255, 255, 255, ${0.02 + Math.sin(time) * 0.01})`;
                        gifContext.fillRect(0, 0, gifCanvas.width, gifCanvas.height);
                        
                        gifTexture.needsUpdate = true;
                        frame++;
                        
                        // Update material
                        if (sharedGifMaterial) {
                            sharedGifMaterial.map.needsUpdate = true;
                            sharedGifMaterial.needsUpdate = true;
                        }
                    } catch (e) {
                        console.warn('Error drawing video frame:', e);
                    }
                }
                
                if (animationMode === 'video') {
                    requestAnimationFrame(animateVideoGif);
                }
            };
            
            animateVideoGif();
        }
        
        // Function to start image-based GIF animation with enhanced effects
        function startImageGifAnimation() {
            if (!currentGifImage) {
                console.warn('No GIF image available for animation');
                return;
            }
            
            console.log('Starting enhanced image GIF animation');
            animationMode = 'image';
            
            // Update right lens with GIF now that it's loaded
            updateRightLensWithGif();
            
            let frame = 0;
            const animateImageGif = () => {
                if (currentGifImage) {
                    // Clear canvas
                    gifContext.clearRect(0, 0, gifCanvas.width, gifCanvas.height);
                    
                    // Create animated background
                    const time = frame * 0.02;
                    const gradient = gifContext.createRadialGradient(
                        gifCanvas.width / 2, gifCanvas.height / 2, 0,
                        gifCanvas.width / 2, gifCanvas.height / 2, Math.max(gifCanvas.width, gifCanvas.height) / 2
                    );
                    gradient.addColorStop(0, `hsl(${(time * 30) % 360}, 20%, 10%)`);
                    gradient.addColorStop(1, `hsl(${(time * 30 + 180) % 360}, 30%, 5%)`);
                    
                    gifContext.fillStyle = gradient;
                    gifContext.fillRect(0, 0, gifCanvas.width, gifCanvas.height);
                    
                    // Draw main image with transformations
                    gifContext.save();
                    gifContext.translate(gifCanvas.width / 2, gifCanvas.height / 2);
                    
                    // Multiple animated layers of the same image for depth
                    for (let layer = 0; layer < 3; layer++) {
                        gifContext.save();
                        
                        const layerTime = time + layer * 0.5;
                        const rotation = Math.sin(layerTime * 0.3) * 0.1;
                        const scale = 0.7 + layer * 0.15 + Math.sin(layerTime * 0.5) * 0.05;
                        const alpha = 0.3 + layer * 0.35;
                        
                        gifContext.rotate(rotation);
                        gifContext.scale(scale, scale);
                        gifContext.globalAlpha = alpha;
                        
                        // Add color tint for each layer
                        if (layer === 1) {
                            gifContext.filter = `hue-rotate(${(time * 20) % 360}deg) saturate(1.2)`;
                        } else if (layer === 2) {
                            gifContext.filter = `hue-rotate(${(time * -15) % 360}deg) contrast(1.1)`;
                        }
                        
                        gifContext.drawImage(
                            currentGifImage,
                            -currentGifImage.width / 2,
                            -currentGifImage.height / 2,
                            currentGifImage.width,
                            currentGifImage.height
                        );
                        
                        gifContext.restore();
                    }
                    
                    gifContext.restore();
                    
                    // Add animated overlay effects
                    gifContext.fillStyle = `rgba(255, 255, 255, ${0.03 + Math.sin(time * 2) * 0.02})`;
                    gifContext.fillRect(0, 0, gifCanvas.width, gifCanvas.height);
                    
                    // Add scanlines effect
                    for (let y = 0; y < gifCanvas.height; y += 4) {
                        gifContext.fillStyle = `rgba(0, 255, 255, ${0.02 + Math.sin(time + y * 0.1) * 0.01})`;
                        gifContext.fillRect(0, y, gifCanvas.width, 1);
                    }
                    
                    gifTexture.needsUpdate = true;
                    frame++;
                    
                    // Update material
                    if (sharedGifMaterial) {
                        sharedGifMaterial.map.needsUpdate = true;
                        sharedGifMaterial.needsUpdate = true;
                    }
                }
                
                if (animationMode === 'image') {
                    requestAnimationFrame(animateImageGif);
                }
            };
            
            animateImageGif();
        }
        
        // Load initial GIF
        loadGif();
        
        // Videos will now switch automatically after 4 loops instead of on a timer
        
        // Use webcam as environment map
        const pmremGenerator = new THREE.PMREMGenerator(renderer);
        let envMap;
        
        // Mode tracking
        let currentMode = 'reflection'; // 'reflection' or 'texture'
        
        // Initialize metal material with webcam reflection
        const createMetalMaterial = () => {
            return new THREE.MeshStandardMaterial({
                color: 0xC0C0C0, // Silver color
                metalness: 0.9,
                roughness: 0.1,
                // Removing envMap reference to avoid shader compilation issues
                // envMap: envMap,
                // envMapIntensity: 1.5,
                clearcoat: 0.5,
                clearcoatRoughness: 0.1
            });
        };
        
        // Initialize video texture material - create different materials for original and mirrored sides
        const createVideoMaterial = (isMirrored = false) => {
            // Clone the webcam texture so we can apply different transformations
            const texture = webcamTexture.clone();
            texture.needsUpdate = true;
            
            // Fix upside-down video by flipping vertically
            texture.wrapT = THREE.RepeatWrapping;
            texture.repeat.y = -1; // Flip vertically to fix upside-down video
            texture.offset.y = 1;  // Adjust offset to compensate
            
            // For the mirrored side, flip the texture horizontally to counteract the geometric mirroring
            if (isMirrored) {
                texture.wrapS = THREE.RepeatWrapping;
                texture.repeat.x = -1; // Flip horizontally
                texture.offset.x = 1;  // Adjust offset to compensate
            }
            
            const material = new THREE.MeshStandardMaterial({
                map: texture,
                metalness: 0.0,  // Reduced metalness for better video visibility
                roughness: 0.1,  // Lower roughness for clearer video
                side: THREE.DoubleSide,
                transparent: false,
                opacity: 1.0,
                emissive: new THREE.Color(0x111111), // Slight emissive to make video more visible
                emissiveMap: texture,
                emissiveIntensity: 0.3
            });
            
            return material;
        };
        
        // Create synthwave glowing material for Eyes meshes
        const createSynthwaveEyesMaterial = () => {
            return new THREE.MeshStandardMaterial({
                color: 0xff0080, // Bright magenta/pink
                emissive: new THREE.Color(0x00ffff), // Cyan emissive glow
                emissiveIntensity: 1.0,
                metalness: 0.0,
                roughness: 0.1,
                transparent: true,
                opacity: 0.9,
                side: THREE.DoubleSide
            });
        };
        
        // Create GIF material for right lens
        const createGifMaterial = () => {
            console.log('Creating GIF material, isGifLoaded:', isGifLoaded);
            
            // Always use the GIF texture (even if it just has test pattern initially)
            const texture = gifTexture.clone();
            texture.needsUpdate = true;
            
            // Fix upside-down texture by flipping vertically
            texture.wrapT = THREE.RepeatWrapping;
            texture.repeat.y = -1; // Flip vertically to fix upside-down texture
            texture.offset.y = 1;  // Adjust offset to compensate
            
            // For the mirrored side, flip the texture horizontally to counteract the geometric mirroring
            texture.wrapS = THREE.RepeatWrapping;
            texture.repeat.x = -1; // Flip horizontally for mirrored mesh
            texture.offset.x = 1;  // Adjust offset to compensate
            
            const material = new THREE.MeshStandardMaterial({
                map: texture,
                metalness: 0.0,  // Reduced metalness for better visibility
                roughness: 0.1,  // Lower roughness for clearer display
                side: THREE.DoubleSide,
                transparent: false,
                opacity: 1.0,
                emissive: new THREE.Color(0x111111), // Slight emissive to make content more visible
                emissiveMap: texture,
                emissiveIntensity: 0.3
            });
            
            console.log('GIF material created with texture:', texture);
            return material;
        };
        
        // Animation time for synthwave effect
        let synthwaveTime = 0;
        
        // Blinking animation state
        let isBlinking = false;
        let blinkProgress = 0;
        const blinkDuration = 0.08; // Duration of one blink in seconds - very fast blinks
        let eyeMeshes = []; // Store references to eye meshes for scaling
        
        // Metal materials array to update
        const modelMaterials = [];
        
        // Create shared materials once to ensure consistent mapping
        let sharedVideoMaterial = null;
        let sharedMetalMaterial = null;
        let sharedSynthwaveEyesMaterial = null;
        let sharedGifMaterial = null;
        
        // Function to update right lens with GIF material once GIF is loaded
        function updateRightLensWithGif() {
            console.log('updateRightLensWithGif called, isGifLoaded:', isGifLoaded, 'gifTexture:', !!gifTexture);
            
            if (gifTexture) {
                // Create the GIF material now that texture is ready
                const gifMaterial = createGifMaterial();
                sharedGifMaterial = gifMaterial;
                
                console.log('Created new GIF material:', gifMaterial);
                
                // Find and update all right lens meshes
                let updatedCount = 0;
                modelMaterials.forEach(item => {
                    if (item.isRightLens) {
                        console.log('Updating right lens mesh:', item.meshName, 'at index:', item.meshIndex);
                        item.mesh.material = gifMaterial;
                        item.material = gifMaterial;
                        updatedCount++;
                    }
                });
                
                console.log('Updated', updatedCount, 'right lens meshes with GIF material');
                return true; // Successfully updated
            } else {
                console.warn('gifTexture not available for right lens update');
            }
            return false; // Not ready yet
        }
        
        // Apply material to all meshes in a model
        const applyMaterialToModel = (model, materialType, isMirrored = false) => {
            let material;
            
            // Create or reuse a shared material for consistent appearance across models
            if (materialType === 'metal') {
                if (!sharedMetalMaterial) {
                    sharedMetalMaterial = createMetalMaterial();
                }
                material = sharedMetalMaterial;
            } else if (materialType === 'video') {
                // For video materials, we need different instances for original and mirrored models
                // to handle the texture matrix transformation
                material = createVideoMaterial(isMirrored);
            }
            
            // Apply the material to all meshes
            model.traverse((child) => {
                if (child.isMesh) {
                    child.material = material;
                    
                    // Add to materials array for later updates
                    if (!modelMaterials.some(item => item.mesh === child)) {
                        modelMaterials.push({
                            mesh: child,
                            material: material,
                            isMirrored: isMirrored
                        });
                    }
                    
                    child.castShadow = true;
                    child.receiveShadow = true;
                }
            });
        };

        // Function to load static environment map as fallback
        function useStaticEnvironmentMap() {
            // Simply create a dark gray background instead of using environment mapping
            // to avoid shader compilation issues
            scene.background = new THREE.Color(0x333333);
            scene.environment = null;
            envMap = null;
        }
        
        // Create dynamic environment map from webcam feed
        function updateEnvironmentMap() {
            try {
                // Only update if video is actually playing
                if (webcamVideo.readyState === webcamVideo.HAVE_ENOUGH_DATA) {
                    webcamTexture.needsUpdate = true;
                    
                    // Skip environment mapping when in texture mode to avoid shader errors
                    if (currentMode === 'texture') {
                        return;
                    }
                    
                    try {
                        // Create a simple 2D texture instead of cube map to avoid shader issues
                        scene.environment = null; // Remove environment mapping
                        
                        // Update all materials directly with simple reflection
                        if (currentMode === 'reflection') {
                            modelMaterials.forEach(item => {
                                if (item.mesh && item.mesh.material) {
                                    // Use simpler reflection approach
                                    item.mesh.material.envMap = null;
                                    item.mesh.material.needsUpdate = true;
                                }
                            });
                        }
                    } catch (renderError) {
                        // If we fail with webcam, fall back to static
                        useStaticEnvironmentMap();
                        // Stop trying to update from webcam
                        return;
                    }
                }
                
                // Continue updating
                requestAnimationFrame(updateEnvironmentMap);
            } catch (error) {
                // Fall back to static environment map
                useStaticEnvironmentMap();
            }
        }
        
        // Start webcam automatically
        function startWebcam() {
            // Check for secure context
            if (window.isSecureContext === false) {
                loadingInfo.innerHTML = "Warning: Site not in secure context. Webcam may not work. Try using HTTPS or localhost.";
                loadingInfo.style.opacity = '1';
                loadingInfo.style.display = 'block';
            }
            
            if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                // Add loading message
                loadingInfo.innerHTML = "Requesting webcam access...";
                loadingInfo.style.opacity = '1';
                loadingInfo.style.display = 'block';
                
                // Try different constraints - ordered from most likely to work to least
                const constraints = [
                    { video: true, audio: false },
                    { video: { width: { ideal: 640 }, height: { ideal: 480 } }, audio: false },
                    { video: { facingMode: "user" }, audio: false },
                    { video: { facingMode: "environment" }, audio: false }
                ];
                
                // Print out available devices for debugging
                navigator.mediaDevices.enumerateDevices()
                    .then(devices => {
                        const videoDevices = devices.filter(device => device.kind === 'videoinput');
                        
                        // Additional debugging for permissions
                        if (navigator.permissions) {
                            navigator.permissions.query({ name: 'camera' })
                                .then(permissionStatus => {
                                    permissionStatus.onchange = () => {
                                        // Permission status changed
                                    };
                                })
                                .catch(err => {
                                    // Error checking camera permission
                                });
                        }
                        
                        if (videoDevices.length === 0) {
                            loadingInfo.innerHTML = "No camera found on this device. Using static reflections instead.<br>Make sure you allow camera access and are using a secure context (https or localhost).";
                            loadingInfo.style.display = 'block';
                            loadingInfo.style.opacity = '1';
                            useStaticEnvironmentMap();
                            setTimeout(() => {
                                loadingInfo.style.opacity = '0';
                            }, 5000);
                            return;
                        }
                        
                        // Try each constraint until one works
                        tryConstraints(constraints, 0);
                    })
                    .catch(err => {
                        // Still try to access webcam even if enumeration fails
                        tryConstraints(constraints, 0);
                    });
                
                function tryConstraints(constraintList, index) {
                    if (index >= constraintList.length) {
                        // All constraints failed, show error
                        loadingInfo.innerHTML = "Could not access any camera. Using static reflections instead.";
                        useStaticEnvironmentMap();
                        setTimeout(() => {
                            loadingInfo.style.opacity = '0';
                        }, 3000);
                        return;
                    }
                    
                    navigator.mediaDevices.getUserMedia(constraintList[index])
                        .then(function(stream) {
                            // Ensure video tracks are enabled and active
                            const videoTracks = stream.getVideoTracks();
                            if (videoTracks.length === 0) {
                                throw new Error("No video tracks found");
                            }
                            
                            // Assign the stream to the video element
                            webcamVideo.srcObject = stream;
                            
                            // Using both play() and the onloadedmetadata event for better compatibility
                            webcamVideo.onloadedmetadata = function() {
                                webcamVideo.play()
                                    .then(() => {
                                        // Make sure we're using a single shared material for all parts
                                        if (!sharedVideoMaterial) {
                                            sharedVideoMaterial = createVideoMaterial();
                                        }
                                        // Apply the same material to all parts for seamless texture
                        modelMaterials.forEach(item => {
                            // Apply appropriate materials: video to left lens, GIF to right lens, synthwave to eyes, metal to others
                            if (item.isEyes) {
                                // Eyes always keep their synthwave glow
                                if (!sharedSynthwaveEyesMaterial) {
                                    sharedSynthwaveEyesMaterial = createSynthwaveEyesMaterial();
                                }
                                item.mesh.material = sharedSynthwaveEyesMaterial;
                                item.material = sharedSynthwaveEyesMaterial;
                            } else if (item.isLeftLens) {
                                const videoMaterial = createVideoMaterial(false);
                                item.mesh.material = videoMaterial;
                                item.material = videoMaterial;
                            } else if (item.isRightLens) {
                                // Right lens keeps the GIF
                                if (!sharedGifMaterial) {
                                    sharedGifMaterial = createGifMaterial();
                                }
                                item.mesh.material = sharedGifMaterial;
                                item.material = sharedGifMaterial;
                            } else {
                                if (!sharedMetalMaterial) {
                                    sharedMetalMaterial = createMetalMaterial();
                                }
                                item.mesh.material = sharedMetalMaterial;
                                item.material = sharedMetalMaterial;
                            }
                        });
                                        
                                        loadingInfo.innerHTML = "Webcam activated and applied as texture successfully!";
                                        loadingInfo.style.opacity = '1';
                                        loadingInfo.style.display = 'block';
                                        setTimeout(() => {
                                            loadingInfo.style.opacity = '0';
                                        }, 3000);
                                        
                                        // Start environment map updates
                                        updateEnvironmentMap();
                                    })
                                    .catch(e => {
                                        loadingInfo.innerHTML = "Error starting video playback. Using static reflections.";
                                        useStaticEnvironmentMap();
                                    });
                            };
                            
                            webcamVideo.onerror = function() {
                                throw new Error("Video element error: " + webcamVideo.error);
                            };
                        })
                        .catch(function(error) {
                            // Try the next constraint
                            tryConstraints(constraintList, index + 1);
                        });
                }
            } else {
                loadingInfo.innerHTML = "Your browser doesn't support webcam access. Using static reflections instead.";
                useStaticEnvironmentMap();
                setTimeout(() => {
                    loadingInfo.style.opacity = '0';
                }, 3000);
            }
        }
        
        // Initialize with static environment map first
        useStaticEnvironmentMap();
        
        // Load GLB model
        const loadingInfo = document.getElementById('loadingInfo');
        const loader = new GLTFLoader();
        
        loader.load(
            // Resource URL
            'copilot.glb',
            // Called when the resource is loaded
            function (gltf) {
                // Create a group to hold both original and mirrored models
                const modelGroup = new THREE.Group();
                scene.add(modelGroup);
                modelGroupRef = modelGroup; // Store reference for click detection
                
                // Store models for later material updates
                const originalModel = gltf.scene.clone();
                const mirroredModel = gltf.scene.clone();
                
                // First apply the scaling transformation to the mirrored model
                mirroredModel.scale.set(-1, 1, 1);
                
                // Apply UV mapping to both models - ensuring they share same UV coordinate space
                // Must do this after scaling the mirrored model
                applyUnifiedUVMapping(originalModel, false);
                applyUnifiedUVMapping(mirroredModel, true);
                
                // Create materials for the model
                const defaultMaterial = createMetalMaterial();
                const leftLensVideoMaterial = createVideoMaterial(false);
                
                // Create the synthwave eyes material
                if (!sharedSynthwaveEyesMaterial) {
                    sharedSynthwaveEyesMaterial = createSynthwaveEyesMaterial();
                }
                
                // Apply materials to the original model
                originalModel.traverse((child) => {
                    if (child.isMesh) {
                        // Check mesh type and apply appropriate material
                        const isLeftLens = child.name === 'Glass';
                        const isEyes = child.name === 'Eyes';
                        
                        if (isEyes) {
                            child.material = sharedSynthwaveEyesMaterial;
                            // Store reference to eye mesh for blinking animation
                            eyeMeshes.push(child);
                        } else if (isLeftLens) {
                            child.material = leftLensVideoMaterial;
                        } else {
                            child.material = defaultMaterial;
                        }
                        
                        modelMaterials.push({
                            mesh: child,
                            material: child.material,
                            isMirrored: false,
                            isLeftLens: isLeftLens,
                            isEyes: isEyes,
                            meshIndex: modelMaterials.length,
                            meshName: child.name
                        });
                        child.castShadow = true;
                        child.receiveShadow = true;
                    }
                });
                
                // Apply materials to the mirrored model (Metal initially, GIF will be applied once ready)
                mirroredModel.traverse((child) => {
                    if (child.isMesh) {
                        const isEyes = child.name === 'Eyes';
                        const isRightLens = child.name === 'Glass'; // Right lens is the Glass mesh on the mirrored model
                        
                        if (isEyes) {
                            child.material = sharedSynthwaveEyesMaterial;
                            // Store reference to eye mesh for blinking animation
                            eyeMeshes.push(child);
                        } else if (isRightLens) {
                            // Start with metal material, will update to GIF once ready
                            child.material = defaultMaterial;
                        } else {
                            child.material = defaultMaterial;
                        }
                        
                        modelMaterials.push({
                            mesh: child,
                            material: child.material,
                            isMirrored: true,
                            isLeftLens: false,
                            isRightLens: isRightLens,
                            isEyes: isEyes,
                            meshIndex: modelMaterials.length,
                            meshName: child.name
                        });
                        child.castShadow = true;
                        child.receiveShadow = true;
                    }
                });
                
                // Add models to the group
                modelGroup.add(originalModel);
                modelGroup.add(mirroredModel);
                
                // Center the entire group
                const box = new THREE.Box3().setFromObject(modelGroup);
                const center = box.getCenter(new THREE.Vector3());
                modelGroup.position.x = -center.x;
                modelGroup.position.y = -center.y;
                modelGroup.position.z = -center.z;
                
                // Adjust camera
                const size = box.getSize(new THREE.Vector3());
                const maxDim = Math.max(size.x, size.y, size.z);
                const fov = camera.fov * (Math.PI / 180);
                let cameraZ = Math.abs(maxDim / 2 / Math.tan(fov / 2));
                cameraZ *= 1.5; // Zoom out a bit
                camera.position.z = cameraZ;
                
                // Update the camera's near and far planes
                camera.near = cameraZ / 100;
                camera.far = cameraZ * 100;
                camera.updateProjectionMatrix();
                
                // Update loading info
                loadingInfo.innerHTML = 'Model loaded successfully! Use mouse to rotate, scroll to zoom.';
                setTimeout(() => {
                    loadingInfo.style.opacity = '0';
                    setTimeout(() => {
                        loadingInfo.style.display = 'none';
                    }, 1000);
                }, 3000);
            },
            // Called while loading is progressing
            function (xhr) {
                const percentComplete = xhr.loaded / xhr.total * 100;
                loadingInfo.innerHTML = 'Loading: ' + Math.round(percentComplete) + '%';
            },
            // Called when loading has errors
            function (error) {
                loadingInfo.innerHTML = 'Error loading model: ' + error.message;
            }
        );

        // Function to apply a consistent UV mapping to the entire model
        function applyUnifiedUVMapping(model, isMirrored = false) {
            // Simplified UV mapping - use standard planar projection
            model.traverse(child => {
                if (child.isMesh && child.geometry) {
                    let uvs = child.geometry.attributes.uv;
                    if (!uvs) {
                        const positions = child.geometry.attributes.position;
                        const count = positions.count;
                        uvs = new THREE.Float32BufferAttribute(count * 2, 2);
                        child.geometry.setAttribute('uv', uvs);
                    }
                    
                    const positionAttribute = child.geometry.attributes.position;
                    const tempVertex = new THREE.Vector3();
                    
                    // Get bounding box for this specific mesh
                    child.geometry.computeBoundingBox();
                    const box = child.geometry.boundingBox;
                    const size = new THREE.Vector3();
                    box.getSize(size);
                    
                    for (let i = 0; i < positionAttribute.count; i++) {
                        tempVertex.fromBufferAttribute(positionAttribute, i);
                        
                        // Use simple planar projection (front view)
                        let u = (tempVertex.x - box.min.x) / size.x;
                        let v = (tempVertex.y - box.min.y) / size.y;
                        
                        // Clamp to 0-1 range
                        u = Math.max(0, Math.min(1, u));
                        v = Math.max(0, Math.min(1, v));
                        
                        uvs.setXY(i, u, v);
                    }
                    
                    uvs.needsUpdate = true;
                }
            });
        }
        
        // Handle window resize
        window.addEventListener('resize', onWindowResize);

        function onWindowResize() {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        }

        // Animation loop
        function animate() {
            requestAnimationFrame(animate);
            
            // Update synthwave time for pulsing glow effect
            synthwaveTime += 0.05;
            
            // Smoothly rotate model to follow mouse cursor
            if (modelGroupRef) {
                // Lerp towards target rotation for smooth movement
                modelGroupRef.rotation.y += (targetRotationY - modelGroupRef.rotation.y) * rotationSmoothness;
                modelGroupRef.rotation.x += (targetRotationX - modelGroupRef.rotation.x) * rotationSmoothness;
            }
            
            // Animate synthwave eyes glow and blinking
            if (sharedSynthwaveEyesMaterial) {
                // Handle blinking animation
                if (isBlinking) {
                    blinkProgress += 0.016; // Assuming 60fps, this is roughly 1/60
                    
                    if (blinkProgress >= blinkDuration) {
                        // Blink completed - reset eye scales
                        isBlinking = false;
                        blinkProgress = 0;
                        
                        // Reset all eye meshes to normal scale
                        eyeMeshes.forEach(eyeMesh => {
                            eyeMesh.scale.set(1, 1, 1);
                        });
                    }
                    
                    // Calculate blink effect (eyes close and open)
                    // Use a sine wave for smooth closing and opening
                    const blinkNormalized = blinkProgress / blinkDuration;
                    const blinkIntensity = Math.sin(blinkNormalized * Math.PI); // 0 -> 1 -> 0
                    
                    // Scale down the eye meshes during blink (shrink effect)
                    const scaleMultiplier = 1 - blinkIntensity * 0.7; // Scale down to 30% at peak blink
                    eyeMeshes.forEach(eyeMesh => {
                        eyeMesh.scale.set(scaleMultiplier, scaleMultiplier * 0.3, scaleMultiplier); // More dramatic Y scaling for eye closing
                    });
                    
                    // Reduce opacity and emissive intensity during blink
                    const baseOpacity = 0.9;
                    const baseEmissiveIntensity = 1.5 + Math.sin(synthwaveTime * 2) * 0.5;
                    
                    sharedSynthwaveEyesMaterial.opacity = baseOpacity * (1 - blinkIntensity * 0.5); // Less opacity reduction since we're scaling
                    sharedSynthwaveEyesMaterial.emissiveIntensity = baseEmissiveIntensity * (1 - blinkIntensity * 0.3);
                } else {
                    // Normal glow animation when not blinking
                    sharedSynthwaveEyesMaterial.opacity = 0.9;
                    sharedSynthwaveEyesMaterial.emissiveIntensity = 1.5 + Math.sin(synthwaveTime * 2) * 0.5;
                    
                    // Ensure eyes are at normal scale when not blinking
                    eyeMeshes.forEach(eyeMesh => {
                        eyeMesh.scale.set(1, 1, 1);
                    });
                }
                
                // Create pulsing synthwave colors
                const hue1 = (Math.sin(synthwaveTime * 1.2) + 1) * 0.5; // 0-1 range
                const hue2 = (Math.sin(synthwaveTime * 0.8 + Math.PI) + 1) * 0.5; // 0-1 range offset
                
                // Mix between magenta/pink and cyan
                const mixedColor = new THREE.Color().setHSL(
                    0.8 + hue1 * 0.3, // Hue: purple to pink range
                    1.0, // Full saturation
                    0.5 + hue2 * 0.3 // Lightness variation
                );
                
                const mixedEmissive = new THREE.Color().setHSL(
                    0.5 + hue2 * 0.3, // Hue: cyan to blue range
                    1.0, // Full saturation
                    0.6 + hue1 * 0.4 // Lightness variation
                );
                
                sharedSynthwaveEyesMaterial.color = mixedColor;
                sharedSynthwaveEyesMaterial.emissive = mixedEmissive;
            }
            
            // Always update video texture if webcam has data
            if (webcamVideo.readyState === webcamVideo.HAVE_ENOUGH_DATA) {
                webcamTexture.needsUpdate = true;
            }
            
            // GIF texture is updated automatically in the GIF animation functions
            // No need to manually update here as it's handled by the canvas drawing
            
            controls.update(); // required if controls.enableDamping = true
            renderer.render(scene, camera);
        }

        animate();
        
        // Set default mode to texture so video is visible on the model
        currentMode = 'texture'; 
        
        // Debug function to manually refresh GIF (can be called from console)
        window.refreshGif = function() {
            loadGif();
        }; 
        
        // Automatically start webcam after page loads
        window.addEventListener('DOMContentLoaded', () => {
            // Give the page a moment to initialize
            setTimeout(() => {
                startWebcam();
                
                // GIF loading is handled automatically in the loadGif() function
                // Try to update right lens material periodically until it succeeds
                const retryInterval = setInterval(() => {
                    if (updateRightLensWithGif()) {
                        clearInterval(retryInterval);
                    }
                }, 1000); // Try every second
                
                // Stop trying after 30 seconds
                setTimeout(() => {
                    clearInterval(retryInterval);
                }, 30000);
            }, 1000);
        });
        
        // Function to toggle between reflection and texture modes
        function toggleMode() {
            const toggleModeButton = document.getElementById('toggleModeButton');
            
            if (currentMode === 'reflection') {
                // Switch to texture mode
                currentMode = 'texture';
                toggleModeButton.textContent = "Switch to Reflection Mode";
                
                // Apply video material only to left lens, GIF to right lens, metal to others, eyes keep synthwave
                modelMaterials.forEach(item => {
                    if (item.isEyes) {
                        // Eyes always keep their synthwave glow
                        item.mesh.material = sharedSynthwaveEyesMaterial;
                        item.material = sharedSynthwaveEyesMaterial;
                    } else if (item.isLeftLens) {
                        const videoMaterial = createVideoMaterial(false);
                        item.mesh.material = videoMaterial;
                        item.material = videoMaterial;
                    } else if (item.isRightLens) {
                        // Right lens keeps the GIF
                        if (!sharedGifMaterial) {
                            sharedGifMaterial = createGifMaterial();
                        }
                        item.mesh.material = sharedGifMaterial;
                        item.material = sharedGifMaterial;
                    } else {
                        if (!sharedMetalMaterial) {
                            sharedMetalMaterial = createMetalMaterial();
                        }
                        item.mesh.material = sharedMetalMaterial;
                        item.material = sharedMetalMaterial;
                    }
                });
                
                loadingInfo.innerHTML = "Video texture mode enabled. Your webcam is now applied to the left lens.";
                loadingInfo.style.opacity = '1';
                loadingInfo.style.display = 'block';
                setTimeout(() => {
                    loadingInfo.style.opacity = '0';
                }, 3000);
                
            } else {
                // Switch back to reflection mode
                currentMode = 'reflection';
                toggleModeButton.textContent = "Switch to Texture Mode";
                
                // Create or reuse a single metal material
                if (!sharedMetalMaterial) {
                    sharedMetalMaterial = createMetalMaterial();
                }
                
                // Apply the same metal material to all parts except Eyes and right lens with GIF
                modelMaterials.forEach(item => {
                    if (item.isEyes) {
                        // Eyes always keep their synthwave glow
                        item.mesh.material = sharedSynthwaveEyesMaterial;
                    } else if (item.isRightLens) {
                        // Right lens keeps the GIF even in reflection mode
                        if (!sharedGifMaterial) {
                            sharedGifMaterial = createGifMaterial();
                        }
                        item.mesh.material = sharedGifMaterial;
                    } else {
                        item.mesh.material = sharedMetalMaterial;
                    }
                });
                
                loadingInfo.innerHTML = "Reflection mode enabled. Your webcam provides environmental reflections.";
                loadingInfo.style.opacity = '1';
                loadingInfo.style.display = 'block';
                setTimeout(() => {
                    loadingInfo.style.opacity = '0';
                }, 3000);
            }
        }
    </script>
</body>
</html>
