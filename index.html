<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-sc        // Mouse move handler for model rotation
        function onMouseMove(event) {
            // Calculate normalized mouse position (-1 to +1)
            mousePosition.x = (event.clientX / window.innerWidth) * 2 - 1;
            mousePosition.y = -(event.clientY / window.innerHeight) * 2 + 1;
            
            // Calculate target rotation based on mouse position
            // Limit rotation to reasonable angles (±15 degrees)
            const maxRotation = Math.PI / 12; // 15 degrees
            targetRotationY = mousePosition.x * maxRotation;
            targetRotationX = -mousePosition.y * maxRotation * 0.5; // Fixed: negative sign to correct inversion
        }  <title>Copilot GLB Viewer</title>
    <style>
        body { margin: 0; overflow: hidden; }
        canvas { display: block; }
        .loading-info {
            position: absolute;
            top: 10px;
            left: 10px;
            color: white;
            background-color: rgba(0, 0, 0, 0.5);
            padding: 5px 10px;
            border-radius: 5px;
            font-family: Arial, sans-serif;
            z-index: 100;
            transition: opacity 0.5s;
        }
        #webcamVideo {
            display: none;
        }
    </style>
</head>
<body>
    <div class="loading-info" id="loadingInfo"></div>
    <video id="webcamVideo" autoplay playsinline muted style="display: none;"></video>
    <video id="mp4Video" autoplay playsinline muted loop preload="auto" style="display: none;">
        <source src="vid.mp4" type="video/mp4">
        Your browser does not support the video tag.
    </video>
    <!-- Include the script at the end of the body for better performance -->
    <script src="share-modal.js" defer></script>
    <script type="importmap">
        {
            "imports": {
                "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
                "three/addons/": "https://unpkg.com/three@0.160.0/examples/jsm/"
            }
        }
    </script>
    <script type="module">
        import * as THREE from 'three';
        import { OrbitControls } from 'three/addons/controls/OrbitControls.js';
        import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';

        // Create scene
        const scene = new THREE.Scene();
        scene.background = new THREE.Color(0x333333);

        // Create camera
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        camera.position.z = 5;

        // Create renderer
        const renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setPixelRatio(window.devicePixelRatio);
        renderer.outputColorSpace = THREE.SRGBColorSpace;
        renderer.shadowMap.enabled = true;
        renderer.shadowMap.type = THREE.PCFSoftShadowMap;
        renderer.toneMapping = THREE.ACESFilmicToneMapping;
        renderer.toneMappingExposure = 1.0;
        document.body.appendChild(renderer.domElement);

        // Add lights
        const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
        scene.add(ambientLight);

        const directionalLight = new THREE.DirectionalLight(0xffffff, 1);
        directionalLight.position.set(5, 10, 7.5);
        directionalLight.castShadow = true;
        scene.add(directionalLight);
        
        // Add point lights for better metallic reflections
        const pointLight1 = new THREE.PointLight(0xffffff, 1, 50);
        pointLight1.position.set(0, 10, 10);
        scene.add(pointLight1);
        
        const pointLight2 = new THREE.PointLight(0xffffff, 0.8, 50);
        pointLight2.position.set(-10, -5, -10);
        scene.add(pointLight2);

        // Add orbit controls
        const controls = new OrbitControls(camera, renderer.domElement);
        controls.enableDamping = true;
        controls.dampingFactor = 0.05;

        // Add raycaster for mesh identification
        const raycaster = new THREE.Raycaster();
        const mouse = new THREE.Vector2();
        let modelGroupRef = null;
        
        // Mouse tracking for model rotation
        const mousePosition = new THREE.Vector2();
        let targetRotationX = 0;
        let targetRotationY = 0;
        const rotationSmoothness = 0.02; // Lower values = smoother/slower rotation

        // Mouse press handler to identify meshes and trigger blink
        function onMouseDown(event) {
            // Trigger blink animation on mouse press
            if (!isBlinking) {
                isBlinking = true;
                blinkProgress = 0;
            }
            
            if (!modelGroupRef) return;
            
            // Calculate mouse position in normalized device coordinates (-1 to +1)
            mouse.x = (event.clientX / window.innerWidth) * 2 - 1;
            mouse.y = -(event.clientY / window.innerHeight) * 2 + 1;

            // Update the raycaster
            raycaster.setFromCamera(mouse, camera);

            // Calculate objects intersecting the picking ray
            const intersects = raycaster.intersectObjects(modelGroupRef.children, true);

            if (intersects.length > 0) {
                const clickedMesh = intersects[0].object;
                
                // Find the mesh in our materials array
                const materialInfo = modelMaterials.find(item => item.mesh === clickedMesh);
                if (materialInfo) {
                    // Mesh clicked - could add UI feedback here
                }
            }
        }

        // Add mousedown event listener
        window.addEventListener('mousedown', onMouseDown, false);
        
        // Add mouse move event listener for model tracking
        window.addEventListener('mousemove', onMouseMove, false);
        
        // Mouse move handler for model rotation
        function onMouseMove(event) {
            // Calculate normalized mouse position (-1 to +1)
            mousePosition.x = (event.clientX / window.innerWidth) * 2 - 1;
            mousePosition.y = -(event.clientY / window.innerHeight) * 2 + 1;
            
            // Calculate target rotation based on mouse position
            // Limit rotation to reasonable angles (±15 degrees)
            const maxRotation = Math.PI / 12; // 15 degrees
            targetRotationY = mousePosition.x * maxRotation;
            targetRotationX = -mousePosition.y * maxRotation * 0.5; // Inverted Y for correct up/down direction
        }

        // Initialize webcam
        const webcamVideo = document.getElementById('webcamVideo');
        const webcamTexture = new THREE.VideoTexture(webcamVideo);
        webcamTexture.minFilter = THREE.LinearFilter;
        webcamTexture.magFilter = THREE.LinearFilter;
        webcamTexture.format = THREE.RGBAFormat;
        webcamTexture.wrapS = THREE.ClampToEdgeWrapping; // Changed from RepeatWrapping
        webcamTexture.wrapT = THREE.ClampToEdgeWrapping; // Changed from RepeatWrapping
        // Don't flip the webcam texture - we'll handle orientation in UV mapping
        webcamTexture.flipY = false;
        
        // Initialize MP4 video
        const mp4Video = document.getElementById('mp4Video');
        let mp4Texture = null; // Don't create texture until video is ready
        
        // Add event listeners for MP4 video
        mp4Video.addEventListener('loadstart', () => {});
        mp4Video.addEventListener('loadeddata', () => {
            // Create texture now that data is loaded
            if (!mp4Texture) {
                mp4Texture = new THREE.VideoTexture(mp4Video);
                mp4Texture.minFilter = THREE.LinearFilter;
                mp4Texture.magFilter = THREE.LinearFilter;
                mp4Texture.format = THREE.RGBAFormat;
                mp4Texture.wrapS = THREE.ClampToEdgeWrapping;
                mp4Texture.wrapT = THREE.ClampToEdgeWrapping;
                mp4Texture.flipY = false;
            }
            // Try to update right lens material now that data is loaded
            setTimeout(() => updateRightLensWithMp4(), 100);
        });
        mp4Video.addEventListener('canplay', () => {
            // Create texture if not already created
            if (!mp4Texture) {
                mp4Texture = new THREE.VideoTexture(mp4Video);
                mp4Texture.minFilter = THREE.LinearFilter;
                mp4Texture.magFilter = THREE.LinearFilter;
                mp4Texture.format = THREE.RGBAFormat;
                mp4Texture.wrapS = THREE.ClampToEdgeWrapping;
                mp4Texture.wrapT = THREE.ClampToEdgeWrapping;
                mp4Texture.flipY = false;
            }
            // Update right lens material when video can play
            updateRightLensWithMp4();
        });
        mp4Video.addEventListener('canplaythrough', () => {});
        mp4Video.addEventListener('playing', () => {
            // Create texture if not already created
            if (!mp4Texture) {
                mp4Texture = new THREE.VideoTexture(mp4Video);
                mp4Texture.minFilter = THREE.LinearFilter;
                mp4Texture.magFilter = THREE.LinearFilter;
                mp4Texture.format = THREE.RGBAFormat;
                mp4Texture.wrapS = THREE.ClampToEdgeWrapping;
                mp4Texture.wrapT = THREE.ClampToEdgeWrapping;
                mp4Texture.flipY = false;
            }
            // Update right lens material when video starts playing
            updateRightLensWithMp4();
        });
        mp4Video.addEventListener('error', (e) => {});
        mp4Video.addEventListener('stalled', () => {});
        mp4Video.addEventListener('suspend', () => {});
        mp4Video.addEventListener('abort', () => {});
        
        // Try to start the MP4 video immediately
        mp4Video.load(); // Explicitly load the video
        
        // Use webcam as environment map
        const pmremGenerator = new THREE.PMREMGenerator(renderer);
        let envMap;
        
        // Mode tracking
        let currentMode = 'reflection'; // 'reflection' or 'texture'
        
        // Initialize metal material with webcam reflection
        const createMetalMaterial = () => {
            return new THREE.MeshStandardMaterial({
                color: 0xC0C0C0, // Silver color
                metalness: 0.9,
                roughness: 0.1,
                // Removing envMap reference to avoid shader compilation issues
                // envMap: envMap,
                // envMapIntensity: 1.5,
                clearcoat: 0.5,
                clearcoatRoughness: 0.1
            });
        };
        
        // Initialize video texture material - create different materials for original and mirrored sides
        const createVideoMaterial = (isMirrored = false) => {
            // Clone the webcam texture so we can apply different transformations
            const texture = webcamTexture.clone();
            texture.needsUpdate = true;
            
            // Fix upside-down video by flipping vertically
            texture.wrapT = THREE.RepeatWrapping;
            texture.repeat.y = -1; // Flip vertically to fix upside-down video
            texture.offset.y = 1;  // Adjust offset to compensate
            
            // For the mirrored side, flip the texture horizontally to counteract the geometric mirroring
            if (isMirrored) {
                texture.wrapS = THREE.RepeatWrapping;
                texture.repeat.x = -1; // Flip horizontally
                texture.offset.x = 1;  // Adjust offset to compensate
            }
            
            const material = new THREE.MeshStandardMaterial({
                map: texture,
                metalness: 0.0,  // Reduced metalness for better video visibility
                roughness: 0.1,  // Lower roughness for clearer video
                side: THREE.DoubleSide,
                transparent: false,
                opacity: 1.0,
                emissive: new THREE.Color(0x111111), // Slight emissive to make video more visible
                emissiveMap: texture,
                emissiveIntensity: 0.3
            });
            
            return material;
        };
        
        // Create synthwave glowing material for Eyes meshes
        const createSynthwaveEyesMaterial = () => {
            return new THREE.MeshStandardMaterial({
                color: 0xff0080, // Bright magenta/pink
                emissive: new THREE.Color(0x00ffff), // Cyan emissive glow
                emissiveIntensity: 1.0,
                metalness: 0.0,
                roughness: 0.1,
                transparent: true,
                opacity: 0.9,
                side: THREE.DoubleSide
            });
        };
        
        // Create MP4 video material for right lens
        const createMp4VideoMaterial = () => {
            // Only create the material if the video is ready and texture exists
            if (mp4Video.readyState < 2 || !mp4Texture) { // HAVE_CURRENT_DATA
                return createMetalMaterial();
            }
            
            // Use the MP4 texture directly
            const texture = mp4Texture.clone();
            texture.needsUpdate = true;
            
            // Fix upside-down video by flipping vertically
            texture.wrapT = THREE.RepeatWrapping;
            texture.repeat.y = -1; // Flip vertically to fix upside-down video
            texture.offset.y = 1;  // Adjust offset to compensate
            
            // For the mirrored side, flip the texture horizontally to counteract the geometric mirroring
            texture.wrapS = THREE.RepeatWrapping;
            texture.repeat.x = -1; // Flip horizontally for mirrored mesh
            texture.offset.x = 1;  // Adjust offset to compensate
            
            const material = new THREE.MeshStandardMaterial({
                map: texture,
                metalness: 0.0,  // Reduced metalness for better video visibility
                roughness: 0.1,  // Lower roughness for clearer video
                side: THREE.DoubleSide,
                transparent: false,
                opacity: 1.0,
                emissive: new THREE.Color(0x111111), // Slight emissive to make video more visible
                emissiveMap: texture,
                emissiveIntensity: 0.3
            });
            
            return material;
        };
        
        // Animation time for synthwave effect
        let synthwaveTime = 0;
        
        // Blinking animation state
        let isBlinking = false;
        let blinkProgress = 0;
        const blinkDuration = 0.08; // Duration of one blink in seconds - very fast blinks
        let eyeMeshes = []; // Store references to eye meshes for scaling
        
        // Metal materials array to update
        const modelMaterials = [];
        
        // Create shared materials once to ensure consistent mapping
        let sharedVideoMaterial = null;
        let sharedMetalMaterial = null;
        let sharedSynthwaveEyesMaterial = null;
        let sharedMp4VideoMaterial = null;
        
        // Function to update right lens with MP4 video material once video is ready
        function updateRightLensWithMp4() {
            if (mp4Video.readyState >= 2 && mp4Texture) { // HAVE_CURRENT_DATA and texture exists
                // Create the MP4 video material now that video is ready
                const mp4VideoMaterial = createMp4VideoMaterial();
                sharedMp4VideoMaterial = mp4VideoMaterial;
                
                // Find and update all right lens meshes
                modelMaterials.forEach(item => {
                    if (item.isRightLens) {
                        item.mesh.material = mp4VideoMaterial;
                        item.material = mp4VideoMaterial;
                    }
                });
                
                return true; // Successfully updated
            }
            return false; // Not ready yet
        }
        
        // Apply material to all meshes in a model
        const applyMaterialToModel = (model, materialType, isMirrored = false) => {
            let material;
            
            // Create or reuse a shared material for consistent appearance across models
            if (materialType === 'metal') {
                if (!sharedMetalMaterial) {
                    sharedMetalMaterial = createMetalMaterial();
                }
                material = sharedMetalMaterial;
            } else if (materialType === 'video') {
                // For video materials, we need different instances for original and mirrored models
                // to handle the texture matrix transformation
                material = createVideoMaterial(isMirrored);
            }
            
            // Apply the material to all meshes
            model.traverse((child) => {
                if (child.isMesh) {
                    child.material = material;
                    
                    // Add to materials array for later updates
                    if (!modelMaterials.some(item => item.mesh === child)) {
                        modelMaterials.push({
                            mesh: child,
                            material: material,
                            isMirrored: isMirrored
                        });
                    }
                    
                    child.castShadow = true;
                    child.receiveShadow = true;
                }
            });
        };

        // Function to load static environment map as fallback
        function useStaticEnvironmentMap() {
            // Simply create a dark gray background instead of using environment mapping
            // to avoid shader compilation issues
            scene.background = new THREE.Color(0x333333);
            scene.environment = null;
            envMap = null;
        }
        
        // Create dynamic environment map from webcam feed
        function updateEnvironmentMap() {
            try {
                // Only update if video is actually playing
                if (webcamVideo.readyState === webcamVideo.HAVE_ENOUGH_DATA) {
                    webcamTexture.needsUpdate = true;
                    
                    // Skip environment mapping when in texture mode to avoid shader errors
                    if (currentMode === 'texture') {
                        return;
                    }
                    
                    try {
                        // Create a simple 2D texture instead of cube map to avoid shader issues
                        scene.environment = null; // Remove environment mapping
                        
                        // Update all materials directly with simple reflection
                        if (currentMode === 'reflection') {
                            modelMaterials.forEach(item => {
                                if (item.mesh && item.mesh.material) {
                                    // Use simpler reflection approach
                                    item.mesh.material.envMap = null;
                                    item.mesh.material.needsUpdate = true;
                                }
                            });
                        }
                    } catch (renderError) {
                        // If we fail with webcam, fall back to static
                        useStaticEnvironmentMap();
                        // Stop trying to update from webcam
                        return;
                    }
                }
                
                // Continue updating
                requestAnimationFrame(updateEnvironmentMap);
            } catch (error) {
                // Fall back to static environment map
                useStaticEnvironmentMap();
            }
        }
        
        // Start webcam automatically
        function startWebcam() {
            // Check for secure context
            if (window.isSecureContext === false) {
                loadingInfo.innerHTML = "Warning: Site not in secure context. Webcam may not work. Try using HTTPS or localhost.";
                loadingInfo.style.opacity = '1';
                loadingInfo.style.display = 'block';
            }
            
            if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                // Add loading message
                loadingInfo.innerHTML = "Requesting webcam access...";
                loadingInfo.style.opacity = '1';
                loadingInfo.style.display = 'block';
                
                // Try different constraints - ordered from most likely to work to least
                const constraints = [
                    { video: true, audio: false },
                    { video: { width: { ideal: 640 }, height: { ideal: 480 } }, audio: false },
                    { video: { facingMode: "user" }, audio: false },
                    { video: { facingMode: "environment" }, audio: false }
                ];
                
                // Print out available devices for debugging
                navigator.mediaDevices.enumerateDevices()
                    .then(devices => {
                        const videoDevices = devices.filter(device => device.kind === 'videoinput');
                        
                        // Additional debugging for permissions
                        if (navigator.permissions) {
                            navigator.permissions.query({ name: 'camera' })
                                .then(permissionStatus => {
                                    permissionStatus.onchange = () => {
                                        // Permission status changed
                                    };
                                })
                                .catch(err => {
                                    // Error checking camera permission
                                });
                        }
                        
                        if (videoDevices.length === 0) {
                            loadingInfo.innerHTML = "No camera found on this device. Using static reflections instead.<br>Make sure you allow camera access and are using a secure context (https or localhost).";
                            loadingInfo.style.display = 'block';
                            loadingInfo.style.opacity = '1';
                            useStaticEnvironmentMap();
                            setTimeout(() => {
                                loadingInfo.style.opacity = '0';
                            }, 5000);
                            return;
                        }
                        
                        // Try each constraint until one works
                        tryConstraints(constraints, 0);
                    })
                    .catch(err => {
                        // Still try to access webcam even if enumeration fails
                        tryConstraints(constraints, 0);
                    });
                
                function tryConstraints(constraintList, index) {
                    if (index >= constraintList.length) {
                        // All constraints failed, show error
                        loadingInfo.innerHTML = "Could not access any camera. Using static reflections instead.";
                        useStaticEnvironmentMap();
                        setTimeout(() => {
                            loadingInfo.style.opacity = '0';
                        }, 3000);
                        return;
                    }
                    
                    navigator.mediaDevices.getUserMedia(constraintList[index])
                        .then(function(stream) {
                            // Ensure video tracks are enabled and active
                            const videoTracks = stream.getVideoTracks();
                            if (videoTracks.length === 0) {
                                throw new Error("No video tracks found");
                            }
                            
                            // Assign the stream to the video element
                            webcamVideo.srcObject = stream;
                            
                            // Using both play() and the onloadedmetadata event for better compatibility
                            webcamVideo.onloadedmetadata = function() {
                                webcamVideo.play()
                                    .then(() => {
                                        // Make sure we're using a single shared material for all parts
                                        if (!sharedVideoMaterial) {
                                            sharedVideoMaterial = createVideoMaterial();
                                        }
                                        // Apply the same material to all parts for seamless texture
                        modelMaterials.forEach(item => {
                            // Apply appropriate materials: video to left lens, MP4 to right lens, synthwave to eyes, metal to others
                            if (item.isEyes) {
                                // Eyes always keep their synthwave glow
                                if (!sharedSynthwaveEyesMaterial) {
                                    sharedSynthwaveEyesMaterial = createSynthwaveEyesMaterial();
                                }
                                item.mesh.material = sharedSynthwaveEyesMaterial;
                                item.material = sharedSynthwaveEyesMaterial;
                            } else if (item.isLeftLens) {
                                const videoMaterial = createVideoMaterial(false);
                                item.mesh.material = videoMaterial;
                                item.material = videoMaterial;
                            } else if (item.isRightLens) {
                                // Right lens keeps the MP4 video
                                if (!sharedMp4VideoMaterial) {
                                    sharedMp4VideoMaterial = createMp4VideoMaterial();
                                }
                                item.mesh.material = sharedMp4VideoMaterial;
                                item.material = sharedMp4VideoMaterial;
                            } else {
                                if (!sharedMetalMaterial) {
                                    sharedMetalMaterial = createMetalMaterial();
                                }
                                item.mesh.material = sharedMetalMaterial;
                                item.material = sharedMetalMaterial;
                            }
                        });
                                        
                                        loadingInfo.innerHTML = "Webcam activated and applied as texture successfully!";
                                        loadingInfo.style.opacity = '1';
                                        loadingInfo.style.display = 'block';
                                        setTimeout(() => {
                                            loadingInfo.style.opacity = '0';
                                        }, 3000);
                                        
                                        // Start environment map updates
                                        updateEnvironmentMap();
                                    })
                                    .catch(e => {
                                        loadingInfo.innerHTML = "Error starting video playback. Using static reflections.";
                                        useStaticEnvironmentMap();
                                    });
                            };
                            
                            webcamVideo.onerror = function() {
                                throw new Error("Video element error: " + webcamVideo.error);
                            };
                        })
                        .catch(function(error) {
                            // Try the next constraint
                            tryConstraints(constraintList, index + 1);
                        });
                }
            } else {
                loadingInfo.innerHTML = "Your browser doesn't support webcam access. Using static reflections instead.";
                useStaticEnvironmentMap();
                setTimeout(() => {
                    loadingInfo.style.opacity = '0';
                }, 3000);
            }
        }
        
        // Initialize with static environment map first
        useStaticEnvironmentMap();
        
        // Load GLB model
        const loadingInfo = document.getElementById('loadingInfo');
        const loader = new GLTFLoader();
        
        loader.load(
            // Resource URL
            'copilot.glb',
            // Called when the resource is loaded
            function (gltf) {
                // Create a group to hold both original and mirrored models
                const modelGroup = new THREE.Group();
                scene.add(modelGroup);
                modelGroupRef = modelGroup; // Store reference for click detection
                
                // Store models for later material updates
                const originalModel = gltf.scene.clone();
                const mirroredModel = gltf.scene.clone();
                
                // First apply the scaling transformation to the mirrored model
                mirroredModel.scale.set(-1, 1, 1);
                
                // Apply UV mapping to both models - ensuring they share same UV coordinate space
                // Must do this after scaling the mirrored model
                applyUnifiedUVMapping(originalModel, false);
                applyUnifiedUVMapping(mirroredModel, true);
                
                // Create materials for the model
                const defaultMaterial = createMetalMaterial();
                const leftLensVideoMaterial = createVideoMaterial(false);
                
                // Create the synthwave eyes material
                if (!sharedSynthwaveEyesMaterial) {
                    sharedSynthwaveEyesMaterial = createSynthwaveEyesMaterial();
                }
                
                // Apply materials to the original model
                originalModel.traverse((child) => {
                    if (child.isMesh) {
                        // Check mesh type and apply appropriate material
                        const isLeftLens = child.name === 'Glass';
                        const isEyes = child.name === 'Eyes';
                        
                        if (isEyes) {
                            child.material = sharedSynthwaveEyesMaterial;
                            // Store reference to eye mesh for blinking animation
                            eyeMeshes.push(child);
                        } else if (isLeftLens) {
                            child.material = leftLensVideoMaterial;
                        } else {
                            child.material = defaultMaterial;
                        }
                        
                        modelMaterials.push({
                            mesh: child,
                            material: child.material,
                            isMirrored: false,
                            isLeftLens: isLeftLens,
                            isEyes: isEyes,
                            meshIndex: modelMaterials.length,
                            meshName: child.name
                        });
                        child.castShadow = true;
                        child.receiveShadow = true;
                    }
                });
                
                // Apply materials to the mirrored model (Metal initially, MP4 video will be applied once ready)
                mirroredModel.traverse((child) => {
                    if (child.isMesh) {
                        const isEyes = child.name === 'Eyes';
                        const isRightLens = child.name === 'Glass'; // Right lens is the Glass mesh on the mirrored model
                        
                        if (isEyes) {
                            child.material = sharedSynthwaveEyesMaterial;
                            // Store reference to eye mesh for blinking animation
                            eyeMeshes.push(child);
                        } else if (isRightLens) {
                            // Start with metal material, will update to MP4 once video is ready
                            child.material = defaultMaterial;
                        } else {
                            child.material = defaultMaterial;
                        }
                        
                        modelMaterials.push({
                            mesh: child,
                            material: child.material,
                            isMirrored: true,
                            isLeftLens: false,
                            isRightLens: isRightLens,
                            isEyes: isEyes,
                            meshIndex: modelMaterials.length,
                            meshName: child.name
                        });
                        child.castShadow = true;
                        child.receiveShadow = true;
                    }
                });
                
                // Add models to the group
                modelGroup.add(originalModel);
                modelGroup.add(mirroredModel);
                
                // Center the entire group
                const box = new THREE.Box3().setFromObject(modelGroup);
                const center = box.getCenter(new THREE.Vector3());
                modelGroup.position.x = -center.x;
                modelGroup.position.y = -center.y;
                modelGroup.position.z = -center.z;
                
                // Adjust camera
                const size = box.getSize(new THREE.Vector3());
                const maxDim = Math.max(size.x, size.y, size.z);
                const fov = camera.fov * (Math.PI / 180);
                let cameraZ = Math.abs(maxDim / 2 / Math.tan(fov / 2));
                cameraZ *= 1.5; // Zoom out a bit
                camera.position.z = cameraZ;
                
                // Update the camera's near and far planes
                camera.near = cameraZ / 100;
                camera.far = cameraZ * 100;
                camera.updateProjectionMatrix();
                
                // Update loading info
                loadingInfo.innerHTML = 'Model loaded successfully! Use mouse to rotate, scroll to zoom.';
                setTimeout(() => {
                    loadingInfo.style.opacity = '0';
                    setTimeout(() => {
                        loadingInfo.style.display = 'none';
                    }, 1000);
                }, 3000);
            },
            // Called while loading is progressing
            function (xhr) {
                const percentComplete = xhr.loaded / xhr.total * 100;
                loadingInfo.innerHTML = 'Loading: ' + Math.round(percentComplete) + '%';
            },
            // Called when loading has errors
            function (error) {
                loadingInfo.innerHTML = 'Error loading model: ' + error.message;
            }
        );

        // Function to apply a consistent UV mapping to the entire model
        function applyUnifiedUVMapping(model, isMirrored = false) {
            // Simplified UV mapping - use standard planar projection
            model.traverse(child => {
                if (child.isMesh && child.geometry) {
                    let uvs = child.geometry.attributes.uv;
                    if (!uvs) {
                        const positions = child.geometry.attributes.position;
                        const count = positions.count;
                        uvs = new THREE.Float32BufferAttribute(count * 2, 2);
                        child.geometry.setAttribute('uv', uvs);
                    }
                    
                    const positionAttribute = child.geometry.attributes.position;
                    const tempVertex = new THREE.Vector3();
                    
                    // Get bounding box for this specific mesh
                    child.geometry.computeBoundingBox();
                    const box = child.geometry.boundingBox;
                    const size = new THREE.Vector3();
                    box.getSize(size);
                    
                    for (let i = 0; i < positionAttribute.count; i++) {
                        tempVertex.fromBufferAttribute(positionAttribute, i);
                        
                        // Use simple planar projection (front view)
                        let u = (tempVertex.x - box.min.x) / size.x;
                        let v = (tempVertex.y - box.min.y) / size.y;
                        
                        // Clamp to 0-1 range
                        u = Math.max(0, Math.min(1, u));
                        v = Math.max(0, Math.min(1, v));
                        
                        uvs.setXY(i, u, v);
                    }
                    
                    uvs.needsUpdate = true;
                }
            });
        }
        
        // Handle window resize
        window.addEventListener('resize', onWindowResize);

        function onWindowResize() {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        }

        // Animation loop
        function animate() {
            requestAnimationFrame(animate);
            
            // Update synthwave time for pulsing glow effect
            synthwaveTime += 0.05;
            
            // Smoothly rotate model to follow mouse cursor
            if (modelGroupRef) {
                // Lerp towards target rotation for smooth movement
                modelGroupRef.rotation.y += (targetRotationY - modelGroupRef.rotation.y) * rotationSmoothness;
                modelGroupRef.rotation.x += (targetRotationX - modelGroupRef.rotation.x) * rotationSmoothness;
            }
            
            // Animate synthwave eyes glow and blinking
            if (sharedSynthwaveEyesMaterial) {
                // Handle blinking animation
                if (isBlinking) {
                    blinkProgress += 0.016; // Assuming 60fps, this is roughly 1/60
                    
                    if (blinkProgress >= blinkDuration) {
                        // Blink completed - reset eye scales
                        isBlinking = false;
                        blinkProgress = 0;
                        
                        // Reset all eye meshes to normal scale
                        eyeMeshes.forEach(eyeMesh => {
                            eyeMesh.scale.set(1, 1, 1);
                        });
                    }
                    
                    // Calculate blink effect (eyes close and open)
                    // Use a sine wave for smooth closing and opening
                    const blinkNormalized = blinkProgress / blinkDuration;
                    const blinkIntensity = Math.sin(blinkNormalized * Math.PI); // 0 -> 1 -> 0
                    
                    // Scale down the eye meshes during blink (shrink effect)
                    const scaleMultiplier = 1 - blinkIntensity * 0.7; // Scale down to 30% at peak blink
                    eyeMeshes.forEach(eyeMesh => {
                        eyeMesh.scale.set(scaleMultiplier, scaleMultiplier * 0.3, scaleMultiplier); // More dramatic Y scaling for eye closing
                    });
                    
                    // Reduce opacity and emissive intensity during blink
                    const baseOpacity = 0.9;
                    const baseEmissiveIntensity = 1.5 + Math.sin(synthwaveTime * 2) * 0.5;
                    
                    sharedSynthwaveEyesMaterial.opacity = baseOpacity * (1 - blinkIntensity * 0.5); // Less opacity reduction since we're scaling
                    sharedSynthwaveEyesMaterial.emissiveIntensity = baseEmissiveIntensity * (1 - blinkIntensity * 0.3);
                } else {
                    // Normal glow animation when not blinking
                    sharedSynthwaveEyesMaterial.opacity = 0.9;
                    sharedSynthwaveEyesMaterial.emissiveIntensity = 1.5 + Math.sin(synthwaveTime * 2) * 0.5;
                    
                    // Ensure eyes are at normal scale when not blinking
                    eyeMeshes.forEach(eyeMesh => {
                        eyeMesh.scale.set(1, 1, 1);
                    });
                }
                
                // Create pulsing synthwave colors
                const hue1 = (Math.sin(synthwaveTime * 1.2) + 1) * 0.5; // 0-1 range
                const hue2 = (Math.sin(synthwaveTime * 0.8 + Math.PI) + 1) * 0.5; // 0-1 range offset
                
                // Mix between magenta/pink and cyan
                const mixedColor = new THREE.Color().setHSL(
                    0.8 + hue1 * 0.3, // Hue: purple to pink range
                    1.0, // Full saturation
                    0.5 + hue2 * 0.3 // Lightness variation
                );
                
                const mixedEmissive = new THREE.Color().setHSL(
                    0.5 + hue2 * 0.3, // Hue: cyan to blue range
                    1.0, // Full saturation
                    0.6 + hue1 * 0.4 // Lightness variation
                );
                
                sharedSynthwaveEyesMaterial.color = mixedColor;
                sharedSynthwaveEyesMaterial.emissive = mixedEmissive;
            }
            
            // Always update video texture if webcam has data
            if (webcamVideo.readyState === webcamVideo.HAVE_ENOUGH_DATA) {
                webcamTexture.needsUpdate = true;
            }
            
            // Always update MP4 video texture if it has data and texture exists
            if (mp4Texture && mp4Video.readyState >= 2 && mp4Video.videoWidth > 0 && mp4Video.videoHeight > 0) {
                mp4Texture.needsUpdate = true;
            }
            
            controls.update(); // required if controls.enableDamping = true
            renderer.render(scene, camera);
        }

        animate();
        
        // Set default mode to texture so video is visible on the model
        currentMode = 'texture'; 
        
        // Debug function to manually start MP4 video (can be called from console)
        window.startMp4Video = function() {
            mp4Video.load();
            return mp4Video.play().then(() => {
                // MP4 video manually started
            }).catch(e => {
                // Failed to manually start MP4
            });
        }; 
        
        // Automatically start webcam after page loads
        window.addEventListener('DOMContentLoaded', () => {
            // Give the page a moment to initialize
            setTimeout(() => {
                startWebcam();
                
                // Start the MP4 video with better error handling
                mp4Video.play().then(() => {
                    // Try to update right lens material after a short delay
                    setTimeout(() => {
                        updateRightLensWithMp4();
                    }, 500);
                }).catch(e => {
                    // Try alternative approach - user gesture might be required
                    document.addEventListener('mousedown', function startVideoOnMouseDown() {
                        mp4Video.play().then(() => {
                            document.removeEventListener('mousedown', startVideoOnMouseDown);
                            
                            // Try to update right lens material after video starts
                            setTimeout(() => {
                                updateRightLensWithMp4();
                            }, 500);
                        }).catch(err => {
                            // Still couldn't start MP4 video
                        });
                    }, { once: true });
                });
                
                // Also try to update right lens material periodically until it succeeds
                const retryInterval = setInterval(() => {
                    if (updateRightLensWithMp4()) {
                        clearInterval(retryInterval);
                    }
                }, 1000); // Try every second
                
                // Stop trying after 30 seconds
                setTimeout(() => {
                    clearInterval(retryInterval);
                }, 30000);
            }, 1000);
        });
        
        // Function to toggle between reflection and texture modes
        function toggleMode() {
            const toggleModeButton = document.getElementById('toggleModeButton');
            
            if (currentMode === 'reflection') {
                // Switch to texture mode
                currentMode = 'texture';
                toggleModeButton.textContent = "Switch to Reflection Mode";
                
                // Apply video material only to left lens, MP4 to right lens, metal to others, eyes keep synthwave
                modelMaterials.forEach(item => {
                    if (item.isEyes) {
                        // Eyes always keep their synthwave glow
                        item.mesh.material = sharedSynthwaveEyesMaterial;
                        item.material = sharedSynthwaveEyesMaterial;
                    } else if (item.isLeftLens) {
                        const videoMaterial = createVideoMaterial(false);
                        item.mesh.material = videoMaterial;
                        item.material = videoMaterial;
                    } else if (item.isRightLens) {
                        // Right lens keeps the MP4 video
                        if (!sharedMp4VideoMaterial) {
                            sharedMp4VideoMaterial = createMp4VideoMaterial();
                        }
                        item.mesh.material = sharedMp4VideoMaterial;
                        item.material = sharedMp4VideoMaterial;
                    } else {
                        if (!sharedMetalMaterial) {
                            sharedMetalMaterial = createMetalMaterial();
                        }
                        item.mesh.material = sharedMetalMaterial;
                        item.material = sharedMetalMaterial;
                    }
                });
                
                loadingInfo.innerHTML = "Video texture mode enabled. Your webcam is now applied to the left lens.";
                loadingInfo.style.opacity = '1';
                loadingInfo.style.display = 'block';
                setTimeout(() => {
                    loadingInfo.style.opacity = '0';
                }, 3000);
                
            } else {
                // Switch back to reflection mode
                currentMode = 'reflection';
                toggleModeButton.textContent = "Switch to Texture Mode";
                
                // Create or reuse a single metal material
                if (!sharedMetalMaterial) {
                    sharedMetalMaterial = createMetalMaterial();
                }
                
                // Apply the same metal material to all parts except Eyes and right lens with MP4
                modelMaterials.forEach(item => {
                    if (item.isEyes) {
                        // Eyes always keep their synthwave glow
                        item.mesh.material = sharedSynthwaveEyesMaterial;
                    } else if (item.isRightLens) {
                        // Right lens keeps the MP4 video even in reflection mode
                        if (!sharedMp4VideoMaterial) {
                            sharedMp4VideoMaterial = createMp4VideoMaterial();
                        }
                        item.mesh.material = sharedMp4VideoMaterial;
                    } else {
                        item.mesh.material = sharedMetalMaterial;
                    }
                });
                
                loadingInfo.innerHTML = "Reflection mode enabled. Your webcam provides environmental reflections.";
                loadingInfo.style.opacity = '1';
                loadingInfo.style.display = 'block';
                setTimeout(() => {
                    loadingInfo.style.opacity = '0';
                }, 3000);
            }
        }
    </script>
</body>
</html>
